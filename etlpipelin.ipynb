{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\ubior\\miniconda3\\lib\\site-packages (3.12.3)\n",
      "Requirement already satisfied: snowflake-sqlalchemy in c:\\users\\ubior\\miniconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\ubior\\miniconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (42.0.5)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (24.2.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (2.9.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (2024.1)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (2.32.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (4.12.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (3.16.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in c:\\users\\ubior\\appdata\\roaming\\python\\python312\\site-packages (from snowflake-connector-python) (4.2.2)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-connector-python) (0.13.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.19 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from snowflake-sqlalchemy) (2.0.32)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from requests<3.0.0->snowflake-connector-python) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from sqlalchemy>=1.4.19->snowflake-sqlalchemy) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install snowflake-connector-python\n",
    "# !pip install load_dotenv\n",
    "# !pip install python-dotenv\n",
    "!pip install snowflake-connector-python snowflake-sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\ubior\\miniconda3\\lib\\site-packages (2.0.32)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from SQLAlchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ubior\\miniconda3\\lib\\site-packages (from SQLAlchemy) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install SQLAlchemy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import snowflake.connector\n",
    "import os\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_env():\n",
    "  load_dotenv(override=True)\n",
    "  account = os.getenv(\"SNOWFLAKE_ACCOUNT\")\n",
    "  user = os.getenv(\"SNOWFLAKE_USER\")\n",
    "  password = os.getenv(\"SNOWFLAKE_PASSWORD\")\n",
    "  warehouse = os.getenv(\"SNOWFLAKE_warehouse\")\n",
    "  database = os.getenv(\"SNOWFLAKE_database\")\n",
    "  schema = os.getenv(\"snowflake_schema\")\n",
    "  return user,account, password, warehouse,database\n",
    "\n",
    "user, account, password, warehouse, database = load_data_from_env()\n",
    "\n",
    "\n",
    "print(user, account, password, warehouse, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_snowflake_database():\n",
    "  conn = snowflake.connector.connect(\n",
    "        user=user,\n",
    "        password=paasword,\n",
    "        account=account,\n",
    "        warehouse=warehouse,\n",
    "        database=database,\n",
    "        schema=schema\n",
    "    )\n",
    "  conn = conn.cursor()\n",
    "  conn.execute('select  current_database()').fetchone()\n",
    "  print('database is connected ')\n",
    "  return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_multi_query(conn):\n",
    "    \"\"\"Executes multiple SQL queries.\"\"\"\n",
    "    try:\n",
    "        queries = [\n",
    "            \"use database ubio_demo;\",\n",
    "            \"use schema ubio_schema;\"\n",
    "        ]\n",
    "        for query in queries:\n",
    "            conn.execute(query)\n",
    "\n",
    "        print(\"Queries executed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing queries: {e}\")\n",
    "     # Ensure connection is closed in case of errors\n",
    "\n",
    "# Assuming 'connection_snowflake_database' function returns an active connection\n",
    "conn = connection_snowflake_database()\n",
    "execute_multi_query(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test database  connection \n",
    "conn.execute(\"select current_database(), current_schema()\").fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_and_schema(conn):\n",
    "  \"\"\"createa new database and schema where will can load the data\"\n",
    "  \"\"\"\n",
    "  try:\n",
    "    query=[\n",
    "        \"create database if not exists uk_demo;\",\n",
    "        \"use database ubio_demo;\",\n",
    "        \"create schema if not exists uk_schema;\",\n",
    "        \"use schema ubio_schema;\"\n",
    "\n",
    "\n",
    "    ]\n",
    "    for query in query:\n",
    "      conn.execute(query)\n",
    "    print(\"database and schema created successfully\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error executing queries: {e}\")\n",
    "conn=connection_snowflake_database()\n",
    "create_database_and_schema(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_format_stage(conn):\n",
    "    \"\"\"\n",
    "    Create a file format and stage in Snowflake, and upload a file to the stage.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define the queries to create file format, stage, and upload the file\n",
    "        file_path =\"/content/railway.csv\"\n",
    "        with open(file_path, 'rb') as file:\n",
    "          file_path = file.read()\n",
    "\n",
    "        queries = [\n",
    "            \"\"\"\n",
    "            CREATE OR REPLACE FILE FORMAT my_csv_file_format\n",
    "            TYPE = 'CSV'\n",
    "            FIELD_DELIMITER = ','\n",
    "            SKIP_HEADER = 2;\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            CREATE OR REPLACE STAGE my_csv_stage\n",
    "            FILE_FORMAT = my_csv_file_format;\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            PUT file:///content/railway.csv @my_csv_stage;\n",
    "            \"\"\"\n",
    "        ]\n",
    "\n",
    "        # Execute each query in the list\n",
    "\n",
    "        for query in queries:\n",
    "            conn.execute(query)\n",
    "            print(f\"Executed: {query.strip().splitlines()[0]}...\")\n",
    "\n",
    "        print(\"File format and stage created successfully.\")\n",
    "        print(\"File loaded into the stage.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing queries: {e}\")\n",
    "\n",
    "\n",
    "conn = connection_snowflake_database()\n",
    "create_file_format_stage(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_if_the_file_is_loaded(conn):\n",
    "    \"\"\"\n",
    "    Check the Snowflake stage to verify if the file is loaded successfully.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Query to list files in the stage\n",
    "        query = \"LIST @my_csv_stage;\"\n",
    "\n",
    "        conn.execute(query)\n",
    "        result = conn.fetchall()\n",
    "\n",
    "        columns = [desc[0] for desc in conn.description]\n",
    "\n",
    "        df = pd.DataFrame(result, columns=columns)\n",
    "        print(\"Stage Contents:\")\n",
    "        print(df)\n",
    "        print(\"File is loaded successfully into the stage.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "\n",
    "conn = connection_snowflake_database()\n",
    "check_if_the_file_is_loaded(conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data_to_table(conn):\n",
    "    \"\"\"\n",
    "    Load data from the Snowflake stage into a table.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List of queries to execute\n",
    "        queries = [\n",
    "            \"\"\"\n",
    "            CREATE OR REPLACE TABLE uk_train_table AS\n",
    "            SELECT\n",
    "                CAST($1 AS STRING) AS Transaction_ID,\n",
    "                CAST($2 AS DATE) AS Date_of_Purchase,\n",
    "                CAST($3 AS TIME) AS Time_of_Purchase,\n",
    "                CAST($4 AS VARCHAR) AS Purchase_Type,\n",
    "                CAST($5 AS VARCHAR) AS Payment_Method,\n",
    "                CAST($6 AS VARCHAR) AS Railcard,\n",
    "                CAST($7 AS VARCHAR) AS Ticket_Class,\n",
    "                CAST($8 AS VARCHAR) AS Ticket_Type,\n",
    "                CAST($9 AS DECIMAL(10,2)) AS Price,\n",
    "                CAST($10 AS VARCHAR) AS Departure_Station,\n",
    "                CAST($11 AS VARCHAR) AS Arrival_Destination,\n",
    "                CAST($12 AS DATE) AS Date_of_Journey,\n",
    "                CAST($13 AS TIME) AS Departure_Time,\n",
    "                CAST($14 AS TIME) AS Arrival_Time,\n",
    "                CAST($15 AS TIME) AS Actual_Arrival_Time,\n",
    "                CAST($16 AS VARCHAR) AS Journey_Status,\n",
    "                CAST($17 AS VARCHAR) AS Reason_for_Delay,\n",
    "                CAST($18 AS VARCHAR) AS Refund_Request\n",
    "            FROM @my_csv_stage\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            SELECT * FROM uk_train_table;\n",
    "            \"\"\"\n",
    "        ]\n",
    "\n",
    "        # Execute each query\n",
    "        for query in queries:\n",
    "\n",
    "            conn.execute(query)\n",
    "\n",
    "\n",
    "            if query.strip().lower().startswith(\"select\"):\n",
    "                result = conn.fetchall()\n",
    "                columns = [desc[0] for desc in conn.description]\n",
    "                df = pd.DataFrame(result, columns=columns)\n",
    "                print(\"Data loaded into DataFrame:\")\n",
    "                print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "    return df\n",
    "\n",
    "conn = connection_snowflake_database()\n",
    "df =load_data_to_table(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_of_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic data transformations and return insights about the DataFrame.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "    Returns:\n",
    "        dict: A dictionary containing column names, null counts, and data types.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = {\n",
    "            \"columns\": df.columns.tolist(),\n",
    "            \"null_counts\": df.isnull().sum().to_dict(),\n",
    "            \"data_types\": df.dtypes.to_dict(),\n",
    "            'change_data_type' : df.PRICE.astype('int').to_dict()}\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error during transformation: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "transformation_of_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deminsional_table(df):\n",
    "  \"\"\"\"create the deminsional table from the dataset\"\"\"\n",
    "  Dim_railcard= df['RAILCARD'].rename({'RAILCARD':'railcard'})\n",
    "  Dim_railcard.index.name ='railcard_id'\n",
    "  Dim_railcard=Dim_railcard.reset_index()\n",
    "  Dim_railcard.to_sql('Dim_railcard', con=engine, if_exists='replace', index=False)\n",
    "  return Dim_railcard\n",
    "\n",
    "create_deminsional_table(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_sql('uk_train_table', con=engine, if_exists='replace', index=False)\n",
    "df.index.name = 'Ticket_id'\n",
    "df = df.reset_index()\n",
    "df.to_sql('uk_train_table', con=engine, if_exists='replace', index=False)\n",
    "df.to_csv('fact_table', index=False)\n",
    "DF=pd.read_csv('fact_table')\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim_railcard= df['RAILCARD'].rename({'RAILCARD':'railcard'})\n",
    "Dim_railcard.index.name ='railcard_id'\n",
    "Dim_railcard=Dim_railcard.reset_index()\n",
    "Dim_railcard.to_sql('Dim_railcard', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_tciket_id(df):\n",
    "  \"\"\"create a table for ticket id\n",
    "  \"\"\"\n",
    "  Dim_Tickets=df[['TICKET_CLASS', 'TICKET_TYPE']]\n",
    "  Dim_Tickets.index.name ='Ticket_id'\n",
    "  Dim_Tickets=Dim_Tickets.reset_index()\n",
    "  Dim_Tickets.to_sql('Dim_Tickets', con=engine, if_exists='replace', index=False)\n",
    "  return Dim_Tickets\n",
    "create_table_tciket_id(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim_Tickets=df[['TICKET_CLASS', 'TICKET_TYPE']]\n",
    "Dim_Tickets.index.name ='Ticket_id'\n",
    "Dim_Tickets=Dim_Tickets.reset_index()\n",
    "Dim_Tickets.to_csv('Dim_Tickets.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create the Dim_station table from the dataset\n",
    "\"\"\"\n",
    "Dim_Station = df[[\"DEPARTURE_STATION\" ,\"ARRIVAL_DESTINATION\"]]\n",
    "Dim_Station.index.name ='Station_id'\n",
    "Dim_Station=Dim_Station.reset_index()\n",
    "Dim_Station=Dim_Station.rename(columns={'DEPARTURE_STATION':'Departure_Station','ARRIVAL_DESTINATION':'Arrival_Destination'})\n",
    "Dim_Station.to_sql('Dim_Station', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "Dim_Station.to_csv('Dim_Station.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create the Refund_ID table from the dataset\"\"\"\n",
    "Refund_ID = df[[\"DATE_OF_JOURNEY\", \"REFUND_REQUEST\"]]\n",
    "Refund_ID.index.name = 'Refund_ID'\n",
    "Refund_ID = Refund_ID.reset_index()\n",
    "Refund_ID = Refund_ID.rename(columns={'DATE_OF_JOURNEY': 'Date_of_Journey', 'REFUND_REQUEST': 'Refund_Request'})\n",
    "Refund_ID.to_sql('Refund_ID', con=engine, if_exists='replace', index=False)\n",
    "Refund_ID.to_csv('Dim_Journeys.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create the Dim_Journeys table from the Dim_refund table\"\"\"\n",
    "Dim_Journeys=df[[\"REASON_FOR_DELAY\" ,\"DEPARTURE_TIME\",\"ARRIVAL_TIME\",\"ACTUAL_ARRIVAL_TIME\" ,\"JOURNEY_STATUS\"]]\n",
    "Dim_Journeys.index.name ='Journey_id'\n",
    "Dim_Journeys=Dim_Journeys.reset_index()\n",
    "Dim_Journeys=Dim_Journeys.rename(columns={'DATE_OF_JOURNEY':'Date_of_Journey' ,'DEPARTURE_TIME':'Departure_Time','ARRIVAL_TIME':'Arrival_Time','ACTUAL_ARRIVAL_TIME':'Actual_Arrival_Time'})\n",
    "Dim_Journeys.to_sql('Dim_Journeys', con=engine, if_exists='replace', index=False)\n",
    "Dim_Journeys.to_csv('Dim_Journeys.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as detetime\n",
    "import datetime as dt\n",
    "\"\"\"\" create the Dim_date table\"\"\"\n",
    "\n",
    "df[\"Date_of_Purchase\"] = pd.to_datetime(df[\"DATE_OF_PURCHASE\"])\n",
    "df[\"day_name\"] = df[\"Date_of_Purchase\"].dt.day_name()\n",
    "df[\"month_name\"] = df[\"Date_of_Purchase\"].dt.month_name()\n",
    "df[\"Year\"] = df[\"Date_of_Purchase\"].dt.year\n",
    "df[\"Quarter\"] = df[\"Date_of_Purchase\"].dt.quarter\n",
    "# Convert 'TIME_OF_PURCHASE' to strings before applying pd.to_datetime\n",
    "df[\"Hour_of_Purchase\"] = pd.to_datetime(df[\"TIME_OF_PURCHASE\"].astype(str)).dt.hour\n",
    "Dim_date = df[[\"Date_of_Purchase\", \"day_name\", \"month_name\", \"Year\", \"Quarter\", \"Hour_of_Purchase\"]]\n",
    "Dim_date.to_sql('Dim_date', con=engine, if_exists='replace', index=False)\n",
    "Dim_date.index.name = 'Date_id'\n",
    "Dim_date = Dim_date.reset_index()\n",
    "Dim_date.to_sql('Dim_date', con=engine, if_exists='replace', index=False)\n",
    "Dim_date.to_csv('Dim_date.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df[\"Hour_of_Purchase\"] = df[\"TIME_OF_PURCHASE\"].apply(lambda x: x.hour)\n",
    "df[\"Minute_of_Purchase\"] = df[\"TIME_OF_PURCHASE\"].apply(lambda x: x.minute)\n",
    "df[\"Second_of_Purchase\"] = df[\"TIME_OF_PURCHASE\"].apply(lambda x: x.second)\n",
    "Dim_time = df[[\"TIME_OF_PURCHASE\", \"Hour_of_Purchase\", \"Minute_of_Purchase\", \"Second_of_Purchase\"]]\n",
    "Dim_time.index.name = 'Time_id'\n",
    "Dim_time = Dim_time.reset_index()\n",
    "Dim_time.to_sql('Dim_time', con=engine, if_exists='replace', index=False)\n",
    "Dim_time.to_csv('Dim_time.csv', index=False)\n",
    "print(Dim_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df[\"Date_of_Journey\"] = pd.to_datetime(df[\"DATE_OF_JOURNEY\"])\n",
    "df[\"day_name_journey\"] = df[\"Date_of_Journey\"].dt.day_name()\n",
    "df[\"month_name_journey\"] = df[\"Date_of_Journey\"].dt.month_name()\n",
    "df[\"Year_journey\"] = df[\"Date_of_Journey\"].dt.year\n",
    "df[\"Quarter\"] = df[\"Date_of_Journey\"].dt.quarter\n",
    "Date_ID_Departure = df[[\"Date_of_Journey\", \"day_name_journey\", \"month_name_journey\", \"Year_journey\", \"Quarter\"]]\n",
    "Date_ID_Departure.index.name = 'Date_ID_Departure'\n",
    "Date_ID_Departure = Date_ID_Departure.reset_index()\n",
    "Date_ID_Departure.to_sql('Date_ID_Departure', con=engine, if_exists='replace', index=False)\n",
    "Date_ID_Departure.to_csv('Date_ID_Departure.csv', index=False)\n",
    "print(Date_ID_Departure)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
